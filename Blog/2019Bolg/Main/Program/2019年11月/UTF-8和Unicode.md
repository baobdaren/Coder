# utf-8和Unicode

* 关注此大佬博客有感[博客](https://blog.csdn.net/zhusongziye/article/details/84261211)  

## 正文

### ASCALL编码

* 计算机一开始保存字符只限于英文字母和部分特殊符号，这只需要7个位就够了。所以使用一个字节来保存

### Unicode

* 可是其他一些国家的文字可不止这些，所以，世界上有个组织“闲来无事”，就把世界上基本所有的字符都对应了一个序号，这个序号从0X000000-0X10FFFF一共好多呢。

### UTF-32/16/8  

* UTF不止一个，分别有32位、16位和8位的方式保存方式，主要是为了节省内存

#### UTF-32

* 这种方式没打算节省内存，直接保存Unicode，但是由于大小端的问题，所以还要细分两种

#### UTF-16

* 这种方式把Unicode字符分为两种，常用字符集0X0000-0XFFFF的常用字符集，和剩下的其他的不知道叫啥。前者使用两个字节表示，后者使用四个字节表示。大小端问题，也细分两种。UTF-16BE 表示大端，UTF-16LE 表示小端。

#### UTF-8

* 这货就是这么来的，通过某些特定位表示使用的字节个数，字节个数从1-4个字节不等。下面细讲
* 细说 `UTF-8`
  * 保存就是为了解读，所以解读方法决定了保存方式：  
    如何解读？首先要获取到底使用了几个字节的信息。这个信息保存在第一个字节。图示  
    |使用字节数|Unicode序号|Unicode八进制|二进制格式|  
    |:---:|:---:|:---:|:---:|
    |1|0-127|0x00-0x7F|`0`XXXXXX|
    |2|128-2047|0x7F-0x7FF|`110`XXXXX，`10`XXXXXX|
    |3|2048-65535|0x7FF-0xFFFF|`1110`XXXX，`10`XXXXXX，`10`XXXXXX|
    |4|65536-...|0x10000-...|`11110`XXX，`10`XXXXXX，`10`XXXXXX，`10`XXXXXX|
    这样就知道到底用了几个字节了，那么要怎样知道具体数值呢？
    这里就是保存和读取的约定了：以Unicode编码的长度，从低到高依次插入Unicode的二进制编码，如：汉字“马”的Unicode编码为\u9a6c，转换成二进制则为：‭10011010，01101100‬，并且需要三个字节保存，所以插入结果就是
    11101001，10101001，10101100 即 E9A9AC
  * 网上有汉字转UTF-8的工具，但是结果都是Unicode的数值

  ```py
  # 本程序创建一个临时文件，并用utf-8的格式保存马字，而后重新打开并按二进制读取，打印为十六进制数字，最后删除临时文件 -- Python
  import os
  FPath = r"./TmpFile"
  with open(FPath, mode="w+", encoding="utf-8") as fd:
      fd.write("马")
  with open(FPath, mode="rb+") as readFd:
      print(readFd.readline()) # b'\xe9\xa9\xac'

  os.remove(FPath)
  ```
